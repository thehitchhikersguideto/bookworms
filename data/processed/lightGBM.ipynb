{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as npp\n",
    "import dotenv\n",
    "import os\n",
    "from data_importer import DataImporter\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import ast\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5040 entries, 0 to 5039\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   book_id          5040 non-null   object \n",
      " 1   title            5040 non-null   object \n",
      " 2   author           5040 non-null   object \n",
      " 3   price            5040 non-null   float64\n",
      " 4   genres           5040 non-null   object \n",
      " 5   language         5040 non-null   object \n",
      " 6   series           5040 non-null   int64  \n",
      " 7   publisher        4733 non-null   object \n",
      " 8   year_published   4987 non-null   object \n",
      " 9   description      4966 non-null   object \n",
      " 10  current_readers  5040 non-null   float64\n",
      " 11  wanted_to_read   5040 non-null   float64\n",
      " 12  num_reviews      5040 non-null   object \n",
      " 13  num_ratings      5040 non-null   object \n",
      " 14  rating           5040 non-null   float64\n",
      " 15  awards           5040 non-null   object \n",
      " 16  primary_lists    5040 non-null   object \n",
      "dtypes: float64(4), int64(1), object(12)\n",
      "memory usage: 669.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Import cleaned data from csv\n",
    "df = pd.read_csv('processed_books.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5040 entries, 0 to 5039\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   book_id          5040 non-null   object \n",
      " 1   genres           5040 non-null   object \n",
      " 2   current_readers  5040 non-null   float64\n",
      " 3   wanted_to_read   5040 non-null   float64\n",
      " 4   num_reviews      5040 non-null   float64\n",
      " 5   num_ratings      5040 non-null   float64\n",
      " 6   rating           5040 non-null   float64\n",
      " 7   awards           5040 non-null   object \n",
      " 8   primary_lists    5040 non-null   object \n",
      "dtypes: float64(5), object(4)\n",
      "memory usage: 354.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection\n",
    "# Drop price, auther, title, description, series, publisher, year_published, language\n",
    "df_used = df.drop(['price', 'author', 'title', 'description', 'series', 'publisher', 'year_published', 'language'], axis = 1)\n",
    "# Remove commas from num_reviews and num_ratings\n",
    "df_used['num_reviews'] = df_used['num_reviews'].str.replace(',', '')\n",
    "df_used['num_ratings'] = df_used['num_ratings'].str.replace(',', '')\n",
    "# Change num_reviews to float64 and num_ratings to float64\n",
    "df_used['num_reviews'] = df_used['num_reviews'].astype('float64')\n",
    "df_used['num_ratings'] = df_used['num_ratings'].astype('float64')\n",
    "df_used.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "for col in df_used.columns:\n",
    "    if df_used[col].dtype == 'O':\n",
    "        try:\n",
    "            df_used[col] = df_used[col].apply(ast.literal_eval)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    if isinstance(df_used[col][0], list):\n",
    "        mlb.fit(df_used[col])\n",
    "        one_hot_col = mlb.transform(df_used[col])\n",
    "        one_hot_df = pd.DataFrame(one_hot_col, columns=mlb.classes_)\n",
    "        df_used = pd.concat([df_used, one_hot_df], axis=1)\n",
    "        df_used.drop(columns=[col], axis=1)\n",
    "        \n",
    "# Drop columns genres, awards, primary_lists\n",
    "df_used = df_used.drop(['genres', 'awards', 'primary_lists'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10277\n"
     ]
    }
   ],
   "source": [
    "\n",
    "renamed_feature_names = []\n",
    "for name in df_used.columns:\n",
    "    renamed_feature_names.append(re.sub('[^0-9a-zA-Z_\\-\\.]+','_',name))\n",
    "\n",
    "df_used.columns = renamed_feature_names\n",
    "for column in df_used.columns:\n",
    "    if column == '_':\n",
    "        df_used.drop(columns=[column], axis=1)\n",
    "print(len(df_used.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Romantic_Times_Reviewers_Choice_Award_RT_Award_Nominee_for_Best_Young_Adult_Paranormal_Fantasy_Novel_2009_',\n",
      "       'The_Kitschies_Nominee_for_Golden_Tentacle_Debut_2020_',\n",
      "       'Alternate_History', 'American', 'Anthologies', 'Art_History', 'Canada',\n",
      "       'Chinese_Literature', 'Cities', 'Dragons', 'Epic_Fantasy', 'Espionage',\n",
      "       'European_History', 'Fantasy_Romance', 'Ghost_Stories',\n",
      "       'Greek_Mythology', 'India', 'Italy', 'Japanese_Literature',\n",
      "       'Military_Science_Fiction', 'Mystery', 'Nordic_Noir', 'Nursing',\n",
      "       'Occult', 'Physics', 'Poetry', 'Rabbits', 'Race', 'Romantic_Suspense',\n",
      "       'Space_Opera', 'Sword_and_Sorcery', 'Tasmania', 'Thelema', 'Theosophy',\n",
      "       'True_Crime', 'Young_Adult_Romance', '_'],\n",
      "      dtype='object')\n",
      "421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim\\AppData\\Local\\Temp\\ipykernel_21740\\2708291778.py:11: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  combined_col = same_name_cols.sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "duplicated_columns = df_used.columns[df_used.columns.duplicated()]\n",
    "# instances = df_used[duplicated_columns].value_counts()\n",
    "\n",
    "print(duplicated_columns)\n",
    "# sum the duplicated columns\n",
    "for column in duplicated_columns:\n",
    "    # Select the duplicated columns with the same name\n",
    "    same_name_cols = df_used.filter(like=column, axis=1)\n",
    "    \n",
    "    # Combine the duplicated columns by adding them up\n",
    "    combined_col = same_name_cols.sum(axis=1)\n",
    "    \n",
    "    # Clip the combined values to 1\n",
    "    combined_col = combined_col.clip(0, 1)\n",
    "    \n",
    "    # Create a new column with the combined values\n",
    "    df_used[column] = combined_col\n",
    "    \n",
    "    # Drop the duplicated columns\n",
    "    df_used = df_used.drop(columns=same_name_cols.columns)\n",
    "\n",
    "print(len(df_used.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5040, 421)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_used.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['book_id'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[183], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m train_data \u001b[39m=\u001b[39m df_used\u001b[39m.\u001b[39msample(frac\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m      2\u001b[0m test_data \u001b[39m=\u001b[39m df_used\u001b[39m.\u001b[39mdrop(train_data\u001b[39m.\u001b[39mindex)\n\u001b[1;32m----> 4\u001b[0m train_set \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39mDataset(train_data\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mrating\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mbook_id\u001b[39;49m\u001b[39m'\u001b[39;49m]), label\u001b[39m=\u001b[39mtrain_data[\u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m test_set \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39mDataset(test_data\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbook_id\u001b[39m\u001b[39m'\u001b[39m]), label\u001b[39m=\u001b[39mtest_data[\u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Tim\\Desktop\\bookworm\\.venv\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tim\\Desktop\\bookworm\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:5399\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5251\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   5252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5253\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5260\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5261\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5262\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5263\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5264\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5397\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5398\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5399\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5400\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5401\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5402\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5403\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5404\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5405\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5406\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5407\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Tim\\Desktop\\bookworm\\.venv\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tim\\Desktop\\bookworm\\.venv\\lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4507\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\Tim\\Desktop\\bookworm\\.venv\\lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Tim\\Desktop\\bookworm\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6932\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6933\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6934\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6935\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6936\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['book_id'] not found in axis\""
     ]
    }
   ],
   "source": [
    "train_data = df_used.sample(frac=0.8, random_state=42)\n",
    "test_data = df_used.drop(train_data.index)\n",
    "\n",
    "train_set = lgb.Dataset(train_data.drop(columns=['rating', 'book_id']), label=train_data['rating'])\n",
    "test_set = lgb.Dataset(test_data.drop(columns=['rating', 'book_id']), label=test_data['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tim\\Desktop\\bookworm\\.venv\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Feature (Romantic_Times_Reviewers_Choice_Award_RT_Award_Nominee_for_Best_Young_Adult_Paranormal_Fantasy_Novel_2009_) appears more than one time.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[155], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lightgbm_model \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39;49mtrain(params, train_set, num_boost_round\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, valid_sets\u001b[39m=\u001b[39;49m[train_set,test_set], early_stopping_rounds\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Tim\\Desktop\\bookworm\\.venv\\lib\\site-packages\\lightgbm\\engine.py:271\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39m# construct booster\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 271\u001b[0m     booster \u001b[39m=\u001b[39m Booster(params\u001b[39m=\u001b[39;49mparams, train_set\u001b[39m=\u001b[39;49mtrain_set)\n\u001b[0;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m is_valid_contain_train:\n\u001b[0;32m    273\u001b[0m         booster\u001b[39m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[1;32mc:\\Users\\Tim\\Desktop\\bookworm\\.venv\\lib\\site-packages\\lightgbm\\basic.py:2605\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   2598\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_network(\n\u001b[0;32m   2599\u001b[0m         machines\u001b[39m=\u001b[39mmachines,\n\u001b[0;32m   2600\u001b[0m         local_listen_port\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mlocal_listen_port\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   2601\u001b[0m         listen_time_out\u001b[39m=\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_out\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m120\u001b[39m),\n\u001b[0;32m   2602\u001b[0m         num_machines\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mnum_machines\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2603\u001b[0m     )\n\u001b[0;32m   2604\u001b[0m \u001b[39m# construct booster object\u001b[39;00m\n\u001b[1;32m-> 2605\u001b[0m train_set\u001b[39m.\u001b[39;49mconstruct()\n\u001b[0;32m   2606\u001b[0m \u001b[39m# copy the parameters from train_set\u001b[39;00m\n\u001b[0;32m   2607\u001b[0m params\u001b[39m.\u001b[39mupdate(train_set\u001b[39m.\u001b[39mget_params())\n",
      "File \u001b[1;32mc:\\Users\\Tim\\Desktop\\bookworm\\.venv\\lib\\site-packages\\lightgbm\\basic.py:1815\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1812\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_init_score_by_predictor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predictor, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, used_indices)\n\u001b[0;32m   1813\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1814\u001b[0m     \u001b[39m# create train\u001b[39;00m\n\u001b[1;32m-> 1815\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lazy_init(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata, label\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel,\n\u001b[0;32m   1816\u001b[0m                     weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, group\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroup,\n\u001b[0;32m   1817\u001b[0m                     init_score\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_score, predictor\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predictor,\n\u001b[0;32m   1818\u001b[0m                     silent\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msilent, feature_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_name,\n\u001b[0;32m   1819\u001b[0m                     categorical_feature\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcategorical_feature, params\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[0;32m   1820\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfree_raw_data:\n\u001b[0;32m   1821\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tim\\Desktop\\bookworm\\.venv\\lib\\site-packages\\lightgbm\\basic.py:1573\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m   1571\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mWrong predictor type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(predictor)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1572\u001b[0m \u001b[39m# set feature names\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_feature_name(feature_name)\n",
      "File \u001b[1;32mc:\\Users\\Tim\\Desktop\\bookworm\\.venv\\lib\\site-packages\\lightgbm\\basic.py:2142\u001b[0m, in \u001b[0;36mDataset.set_feature_name\u001b[1;34m(self, feature_name)\u001b[0m\n\u001b[0;32m   2140\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLength of feature_name(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(feature_name)\u001b[39m}\u001b[39;00m\u001b[39m) and num_feature(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_feature()\u001b[39m}\u001b[39;00m\u001b[39m) don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt match\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2141\u001b[0m     c_feature_name \u001b[39m=\u001b[39m [c_str(name) \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m feature_name]\n\u001b[1;32m-> 2142\u001b[0m     _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_DatasetSetFeatureNames(\n\u001b[0;32m   2143\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   2144\u001b[0m         c_array(ctypes\u001b[39m.\u001b[39;49mc_char_p, c_feature_name),\n\u001b[0;32m   2145\u001b[0m         ctypes\u001b[39m.\u001b[39;49mc_int(\u001b[39mlen\u001b[39;49m(feature_name))))\n\u001b[0;32m   2146\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Tim\\Desktop\\bookworm\\.venv\\lib\\site-packages\\lightgbm\\basic.py:125\u001b[0m, in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39m    The return value from C API calls.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 125\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(_LIB\u001b[39m.\u001b[39mLGBM_GetLastError()\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;31mLightGBMError\u001b[0m: Feature (Romantic_Times_Reviewers_Choice_Award_RT_Award_Nominee_for_Best_Young_Adult_Paranormal_Fantasy_Novel_2009_) appears more than one time."
     ]
    }
   ],
   "source": [
    "lightgbm_model = lgb.train(params, train_set, num_boost_round=1000, valid_sets=[train_set,test_set], early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_list = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
